from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.multioutput import MultiOutputRegressor
import numpy as np
import nltk
from nltk.stem import PorterStemmer, WordNetLemmatizer
from nltk.corpus import wordnet

def preprocesses():
    data = np.load("fana_data_700_new.npy")

    features = data[:,0]
    target = data[:,1:9]

    lemmatizer = WordNetLemmatizer()
    stemmer = PorterStemmer()


    for sentence in features:
        text = nltk.word_tokenize(sentence)
        for t in text:
            new_text=stemmer.stem(t)
            lemmatizer.lemmatize(t, wordnet.VERB)
            print(new_text)


    #print(features.shape)
    #print(target.shape)
    

def train():

    X = np.random.random((10,3))
    y = np.random.random((10,2))
    X2 = np.random.random((7,3))

    svr = SVR(gamma="auto")
    regr = MultiOutputRegressor(svr)

    regr.fit(X,y)
    regr.predict(X2)

def main():
    preprocesses()

if __name__ == "__main__":
    main()
